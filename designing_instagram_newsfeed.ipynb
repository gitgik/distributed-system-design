{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Instagram Feed\n",
    "\n",
    "A feed is a constantly updating scrollable list of posts, photos, videos, and status updates from all the people and pages a user follows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements and System Goals\n",
    "\n",
    "### Functional requirements\n",
    "1. Feeds may contain images, videos and text.\n",
    "2. Feeds are generated from the posts belonging to the pages and people the user follows.\n",
    "3. The service should support appending new posts as they arrive to the feed for all active users\n",
    "\n",
    "### Non-functional requirements \n",
    "1. The system should be able to generate a user's newsfeed in real-time - maximum latency seen by the end user shoudl be about 2s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Capacity Estimation and Constraints\n",
    "Assume on average a user has 300 friends and follows 200 pages.\n",
    "\n",
    "**Traffic Estimates:** A typical user checks their feed about 5 times per day on average. If we have 200 million daily active users, then:\n",
    "\n",
    "```text\n",
    "Per day: 200M * 5 => 1B requests\n",
    "\n",
    "Per second:   1B / 86400 sec => 11500 reqs/sec \n",
    "```\n",
    "\n",
    "**Storage estimates:** Assume we have on average 500 posts for each user's feed that we want to keep in memory for fast fetching. \n",
    "Let's also assume on average that each post would be about 100KB in size (gifs, photos and videos combined). This means we need about 100KB X 500 = 5 MB per user. \n",
    "To store all this data for all active users, we'll need:\n",
    "\n",
    "```text\n",
    "    200 M active users * 5MB  ~= 1 Petabyte of memory\n",
    "```\n",
    "\n",
    "If a server can hold 100 GB memory, we'd need about 10000 machines to keep the top 500 posts in memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System APIs\n",
    "> By defining the system APIs, you are explicitly stating what is expected from the system\n",
    "\n",
    "We'll have REST APIs to expose our service's functionality.\n",
    "\n",
    "**Getting User Feed**\n",
    "\n",
    "```python\n",
    "getUserFeed(\n",
    "    api_dev_key: int,  # Key of a registered user, used to throttle users based on their allocated quota.\n",
    "    user_id: int,  # The Id of the user whom the system will generate the feed.\n",
    "    since_id: int,  # (Optional) Return results with IDs more recent than this ID.\n",
    "    count: int ,   # (Optional) Specifies number of feed items to try and retrieve.\n",
    "    max_id: int,   # (Optional) Returns results with IDs younger than the specified ID.\n",
    "    exclude_replies  # (Optional) Prevents replies from appearing in the results.\n",
    "```\n",
    "\n",
    "**Returns:** (JSON) object containing a list of feed items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Database Design\n",
    "There are three major objects: User, Entity (Business Accounts, Brands, Pages etc) and Post (A feed item). \n",
    "    * A user follows entities and other users.\n",
    "    * Users and entities can both post a Post which can contain text, images, or videos\n",
    "    * Each Post has a UserID of the user who created it. \n",
    "    * For simplicity, let's assume only users can create a post.\n",
    "    * A Post can optionally have an EntityID that points to the page or business entity where the post was created.\n",
    "\n",
    "If we use a relational DB, we can model two relations: User-to-Entity and Post-to-Media relation. Since each user can be friends with many people and follow a lot of entities, we can store this relation in a separate table. \n",
    "\n",
    "| Users |                      |\n",
    "|:----:|:-----------------------|\n",
    "|PK   |  **UserID: int**         |\n",
    "|     | Name: varchar(32)       |\n",
    "|     | Email: varchar(32)      |\n",
    "|     | DOB: datetime           |\n",
    "|     | CreatedAt: datetime  |\n",
    "|     | LastLogin: datetime     |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    " | Entity |                      |\n",
    "|:----:|:-----------------------|\n",
    "|PK   |  **EntityID: int**         |\n",
    "|     | Name: varchar(32)       |\n",
    "|     | Type: int               |\n",
    "|     | Email: varchar(32)           |\n",
    "|     | Description: varchar(512)      |\n",
    "|     | Phone: varchar(12)           |\n",
    "|     | CreatedAt: datetime  |\n",
    "|     | LastLogin: datetime     |\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| UserFollow |                      |\n",
    "|:----:|:-----------------------|\n",
    "|PK   |  (**UserID, EntityOrFriendID: int**)          |\n",
    "|     |  Type: enum (0, 1) |\n",
    "\n",
    "The **Type** column above identifies if an entity being followed is a user or an entity.\n",
    "We can also have a table for the Media to Post relation.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| Post |                      |\n",
    "|:----:|:-----------------------|\n",
    "|PK   |  **PostID: int**         |\n",
    "|     | UserID: int |\n",
    "|     | Contents: varchar(256)      |\n",
    "|     | EntityID: int           |\n",
    "|     | Latitute: int           |\n",
    "|     | Longitude: int  |\n",
    "|     | CreatedAt: datetime     |\n",
    "|    |  Likes: int         |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| Media |                      |\n",
    "|:----:|:-----------------------|\n",
    "|     | MediaID: int |\n",
    "|     | Type: enum |\n",
    "|     | Description: varchar(256)      |\n",
    "|     | Path: int           |\n",
    "|     | Latitute: int           |\n",
    "|     | Longitude: int  |\n",
    "|     | CreatedAt: datetime     |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| PostMedia |                      |\n",
    "|:----:|:-----------------------|\n",
    "|PK   |  (**PostID, MediaID: int**)          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. High Level System Design\n",
    "At a high level we have two system parts:\n",
    "Feed generation and Feed publishing.\n",
    "\n",
    "#### Feed Generation\n",
    "Whenever our system receives a request to generate a feed for a user, we'll perform these steps:\n",
    "    1. Get all UserIDs and EntityIDs that the user follows\n",
    "    2. Retrieve latest and most popular posts for those IDs\n",
    "    3. Rank them based on relevance to the user. This is the user's current feed.\n",
    "    4. Store the feed in a cache.\n",
    "    5. Return top posts to be rendered on the user's feed.\n",
    "    6. On front-end, when the user reaches the end of the loaded feed, fetch the next posts from the cache server.\n",
    "    7. Periodically rank and add new posts to the user's feed.\n",
    "    8. Notify user that there are new posts\n",
    "    \n",
    "#### Feed Publishing\n",
    "When the user loads her feed, she has request and pull posts from the server. When she reaches the end of her current feed, the server can push new posts.\n",
    "\n",
    "Should the server notify the user then the user can pull, or should the server just push new posts?\n",
    "\n",
    "At a high level, we'll have the following components:\n",
    "\n",
    "1. Web Servers: maintain the connection to the user to allow data transfer between user client and server.\n",
    "2. Application Server: executes the work of storing new posts in the DB servers, as well as retrieval from the DB and pushing the feed to the user.\n",
    "3. Metadata DB and Cache: store metadata about Users, Pages, Businesses, etc\n",
    "4. Post DB and Cache: to store metadata about posts and their contents\n",
    "5. Video/Photo storage and Cache: Blob storage to store all media in the posts\n",
    "6. Feed generation service: to get and rank relevant posts for a user and generate the feed, and store in the cache.\n",
    "7. Feed notification service: to notify user that there are newer feed posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Component Design\n",
    "\n",
    "Let's look at generating the feed. The query would look something like this:\n",
    "\n",
    "~~~mysql\n",
    "SELECT PostID FROM Post WHERE UserID IN\n",
    "    (SELECT EntityOrFriendID FROM UserFollow WHERE UserID = <user_id> AND type = 0) -- user\n",
    "    UNION\n",
    "SELECT PostID from Post WHERE EntityID IN\n",
    "    (SELECT EntityID FROM UserFollow WHERE UserID = <user_id> AND type = 1) -- entity\n",
    "ORDER BY CreatedAt DESC \n",
    "LIMIT 100\n",
    "~~~\n",
    "We want to avoid a direct query to the DB due to high latency. \n",
    "\n",
    "We also want to avoid generating the feed when a user loads the page because it will be slow and have a high latency.\n",
    "\n",
    "Also, the server notifying about new posts to user with lots of followers could lead to heavy loads. To improve on all this, we can pre-generate the feed and store it in memory.\n",
    "\n",
    "### Offline generation \n",
    "We can have severs dedicated to continuously generate feeds and store in memory. When a user requests for the new posts, we can simply serve it from the stored location. Therefore a user's feed is compiled not on load but on a regular basis and returned to users whenever they request it.\n",
    "\n",
    "\n",
    "When the servers need to generate feed for a user, we first query to see last time the feed was generated. New feed will be generated from that time onwards.\n",
    "\n",
    "We can store this data in a hash table where key = UserID and value is:\n",
    "```c\n",
    "Struct { \n",
    "    LinkedHashMap <PostID, Post> posts;\n",
    "    DateTime lastGenerated;\n",
    "}\n",
    "```\n",
    "\n",
    "We can store the PostIDs in a Linked HashMap (A hash table + doubly-linked list implementation), which will allow for jumping to any post at constant time but also iterate through the map easily. (The linked list maintains the order in which keys were inserted into the map)\n",
    "\n",
    "When fetching new posts, the client sends the last PostID the user currently sees in their feed, then the server can jump to that PostID in our hashmap and return next batch of posts from there.\n",
    "\n",
    "#### How many feeds should we store in memory?\n",
    "Initially we can store 500 posts per user, but this number can be adjusted based on the usage pattern for a user. Users who never browse past 10 feeds can have 100 posts in memory.\n",
    "\n",
    "#### Should we generate for all users?\n",
    "No. Lots of users won't log in frequently.\n",
    "We can use a LRU based cache to remove users from memory that haven't accessed their feed for a long time.\n",
    "\n",
    "We can also use machine learning to pre-generate their feed based on their login patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Publishing\n",
    "The process of pushing a post to all followers is call **fanout**.\n",
    "\n",
    "Two approaches to publishing:\n",
    "1. **Pull model (Fanout on load):** Clients pull data either on intervals or manually when needed. The problem with this approach is\n",
    "    \n",
    "    a. New data might not be shown to users until they do a pull request\n",
    "    \n",
    "    b. Most of the time pulls return empty responses: a wasted resource that could have been avoided.\n",
    "    \n",
    "2. **Push model (Fanout on write):** Immediately push a post to all followers once a user posts it. Advantage here is you don't need to iterate through your friends list to get their feeds, thus significantly reducing read operations. Users have to maintain a long-poll request with the server for receiving updates. A possible problem with this approach is when a celeb user has millions of followers, the server has to push updates to a lot of people.\n",
    "\n",
    "3. **Hybrid:** We can combine push and pull models. We stop pushing posts from celeb users with lots of followers. We can let their followers pull updates. By doing this, we can save a huge number of fanout resources. Alternatively, we can limit the push fanout to only followers who are online.\n",
    "\n",
    "#### How many feeds should we return to client?\n",
    "Say 20 per request. Also, different clients (mobile vs desktop) fetch different number of posts due to differences in screen size and bandwidth usage.\n",
    "\n",
    "We can notify the users on desktop where data usage is cheap. For mobile devices, data usage is expensive, so we can choose not to push data but instead to let users *pull to refresh* to get new posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feed Ranking\n",
    "To rank posts in a newsfeed, we can use creation time of the posts. However today's\n",
    "ranking algorithms are doing more to ensure important posts are ranked higher.\n",
    "\n",
    "The idea is to select key **features** that make a post important, \n",
    "combining them and calculating the final ranking score.\n",
    "\n",
    "These features include:\n",
    "* creation time\n",
    "* number of likes\n",
    "* number of comments\n",
    "* number of shares, \n",
    "* time of the updates\n",
    "\n",
    "We can also check the effectiveness of the ranking system by evaluating if it has increased user retention and add revenue etc. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
